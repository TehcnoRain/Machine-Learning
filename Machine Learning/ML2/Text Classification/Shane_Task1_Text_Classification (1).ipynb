{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification\n",
    "## This notebook outlines the usage of NLP Feature extraction (CountVectorizer, TfidfVectorizer) in classification of text documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a few categories fro the entire 20 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch documents for these 2 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857 documents\n",
      "2 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(f\"{len(data.filenames)} documents\")\n",
    "print(f\"{len(data.target_names)} categories\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a pipeline combining a text feature extractor with a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    'SGDClassifier': SGDClassifier(tol=1e-3),\n",
    "    'Multinomial Naïve Bayes': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Support Vector Machines': SVC(),\n",
    "    'Decision Trees': DecisionTreeClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using algorithm: SGDClassifier\n",
      "Using algorithm: Multinomial Naïve Bayes\n",
      "Using algorithm: Logistic Regression\n",
      "Using algorithm: Support Vector Machines\n",
      "Using algorithm: Decision Trees\n"
     ]
    }
   ],
   "source": [
    "for algo_name, algorithm in algorithms.items():\n",
    "    print(f\"Using algorithm: {algo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voting Classifier\n",
    "# ensemble_clf = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('sgd', SGDClassifier(tol=1e-3)),\n",
    "#         ('nb', MultinomialNB()),\n",
    "#         ('logreg', LogisticRegression()),  # Add Logistic Regression\n",
    "#         ('svm', SVC(probability=True)),\n",
    "#         ('tree', DecisionTreeClassifier())\n",
    "#     ],\n",
    "#     voting='hard'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', algorithm),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify parameter grid\n",
    "- 'vect__max_df': (0.5, 0.75, 1.0)\n",
    "- 'vect__max_features': (None, 5000, 10000, 50000)\n",
    "- 'vect__ngram_range': ((1, 1), (1, 2))\n",
    "- 'tfidf__use_idf': (True, False)\n",
    "- 'tfidf__norm': ('l1', 'l2')\n",
    "- 'clf__max_iter': (20,)\n",
    "- 'clf__alpha': (0.00001, 0.000001)\n",
    "- 'clf__penalty': ('l2', 'elasticnet')\n",
    "- 'clf__max_iter': (10, 50, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "\n",
    "if algo_name == 'SGDClassifier':\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000, 50000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2'),\n",
    "        'clf__max_iter': (20,),\n",
    "        'clf__alpha': (0.00001, 0.000001),\n",
    "        'clf__penalty': ('l2', 'elasticnet'),\n",
    "    }\n",
    "elif algo_name == 'Multinomial Naïve Bayes':\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000, 50000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2'),\n",
    "    }\n",
    "elif algo_name == 'Logistic Regression':\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000, 50000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2'),\n",
    "        'clf__max_iter': (20,),\n",
    "        'clf__C': (1, 0.1, 0.01),\n",
    "    }\n",
    "elif algo_name == 'Decision Trees':\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000, 50000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2'),\n",
    "        'clf__criterion': ('gini', 'entropy'),\n",
    "        'clf__splitter': ('best', 'random'),\n",
    "        'clf__max_depth': (None, 10, 20, 30),\n",
    "        'clf__min_samples_split': (2, 5, 10),\n",
    "        'clf__min_samples_leaf': (1, 2, 4),\n",
    "        'clf__max_features': (None, 'sqrt', 'log2'),\n",
    "    }\n",
    "elif algo_name == 'Support Vector Machines':\n",
    "    parameters = {\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000, 50000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2'),\n",
    "        'clf__C': (1, 0.1, 0.01),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best parameters for both the feature extraction and the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a GridSearch with the pipeline and parameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 41472 candidates, totalling 207360 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;, DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__criterion&#x27;: (&#x27;gini&#x27;, &#x27;entropy&#x27;),\n",
       "                         &#x27;clf__max_depth&#x27;: (None, 10, 20, 30),\n",
       "                         &#x27;clf__max_features&#x27;: (None, &#x27;sqrt&#x27;, &#x27;log2&#x27;),\n",
       "                         &#x27;clf__min_samples_leaf&#x27;: (1, 2, 4),\n",
       "                         &#x27;clf__min_samples_split&#x27;: (2, 5, 10),\n",
       "                         &#x27;clf__splitter&#x27;: (&#x27;best&#x27;, &#x27;random&#x27;),\n",
       "                         &#x27;tfidf__norm&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;),\n",
       "                         &#x27;tfidf__use_idf&#x27;: (True, False),\n",
       "                         &#x27;vect__max_df&#x27;: (0.5, 0.75, 1.0),\n",
       "                         &#x27;vect__max_features&#x27;: (None, 5000, 10000, 50000),\n",
       "                         &#x27;vect__ngram_range&#x27;: ((1, 1), (1, 2))},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                                       (&#x27;clf&#x27;, DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;clf__criterion&#x27;: (&#x27;gini&#x27;, &#x27;entropy&#x27;),\n",
       "                         &#x27;clf__max_depth&#x27;: (None, 10, 20, 30),\n",
       "                         &#x27;clf__max_features&#x27;: (None, &#x27;sqrt&#x27;, &#x27;log2&#x27;),\n",
       "                         &#x27;clf__min_samples_leaf&#x27;: (1, 2, 4),\n",
       "                         &#x27;clf__min_samples_split&#x27;: (2, 5, 10),\n",
       "                         &#x27;clf__splitter&#x27;: (&#x27;best&#x27;, &#x27;random&#x27;),\n",
       "                         &#x27;tfidf__norm&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;),\n",
       "                         &#x27;tfidf__use_idf&#x27;: (True, False),\n",
       "                         &#x27;vect__max_df&#x27;: (0.5, 0.75, 1.0),\n",
       "                         &#x27;vect__max_features&#x27;: (None, 5000, 10000, 50000),\n",
       "                         &#x27;vect__ngram_range&#x27;: ((1, 1), (1, 2))},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__criterion': ('gini', 'entropy'),\n",
       "                         'clf__max_depth': (None, 10, 20, 30),\n",
       "                         'clf__max_features': (None, 'sqrt', 'log2'),\n",
       "                         'clf__min_samples_leaf': (1, 2, 4),\n",
       "                         'clf__min_samples_split': (2, 5, 10),\n",
       "                         'clf__splitter': ('best', 'random'),\n",
       "                         'tfidf__norm': ('l1', 'l2'),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__max_features': (None, 5000, 10000, 50000),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.907\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for Decision Trees: [0.84598123 0.84133007 0.850612   ... 0.63246294 0.57180063 0.56825785]\n",
      "All Scores:\n",
      "Decision Trees: [0.84598123 0.84133007 0.850612   ... 0.63246294 0.57180063 0.56825785]\n"
     ]
    }
   ],
   "source": [
    "all_scores = {}\n",
    "all_scores[algo_name] = grid_search.cv_results_['mean_test_score']\n",
    "print(f\"Scores for {algo_name}: {all_scores[algo_name]}\")\n",
    "print(\"All Scores:\")\n",
    "for algo_name, scores in all_scores.items():\n",
    "    print(f\"{algo_name}: {scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "\tclf__criterion: 'entropy'\n",
      "\tclf__max_depth: 20\n",
      "\tclf__max_features: None\n",
      "\tclf__min_samples_leaf: 1\n",
      "\tclf__min_samples_split: 2\n",
      "\tclf__splitter: 'random'\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: 10000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best algorithm:  DecisionTreeClassifier(criterion='entropy', max_depth=20, splitter='random')\n",
      "Best parameters:  {'clf__criterion': 'entropy', 'clf__max_depth': 20, 'clf__max_features': None, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__splitter': 'random', 'tfidf__norm': 'l1', 'tfidf__use_idf': False, 'vect__max_df': 0.75, 'vect__max_features': 10000, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best algorithm: \", grid_search.best_estimator_.named_steps['clf'])\n",
    "print(\"Best parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(max_df=0.75, max_features=10000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer(norm=&#x27;l1&#x27;, use_idf=False)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                                        splitter=&#x27;random&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                 CountVectorizer(max_df=0.75, max_features=10000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer(norm=&#x27;l1&#x27;, use_idf=False)),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=20,\n",
       "                                        splitter=&#x27;random&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_df=0.75, max_features=10000, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer(norm=&#x27;l1&#x27;, use_idf=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=20, splitter=&#x27;random&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(max_df=0.75, max_features=10000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('tfidf', TfidfTransformer(norm='l1', use_idf=False)),\n",
       "                ('clf',\n",
       "                 DecisionTreeClassifier(criterion='entropy', max_depth=20,\n",
       "                                        splitter='random'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.919\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        93\n",
      "           1       0.89      0.94      0.91        79\n",
      "\n",
      "    accuracy                           0.92       172\n",
      "   macro avg       0.92      0.92      0.92       172\n",
      "weighted avg       0.92      0.92      0.92       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the ensemble model\n",
    "# ensemble_clf.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the ensemble model\n",
    "# y_pred_ensemble = ensemble_clf.predict(X_test)\n",
    "# accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
    "# report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
    "\n",
    "# print(f\"Accuracy of the Ensemble Model: {accuracy_ensemble:.3f}\")\n",
    "# print(\"Classification Report for the Ensemble Model:\\n\", report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to classify a piece of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Predicted category: alt.atheism\n",
      "Document 2 - Predicted category: talk.religion.misc\n",
      "Document 3 - Predicted category: alt.atheism\n",
      "Document 4 - Predicted category: talk.religion.misc\n",
      "Document 5 - Predicted category: talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# Predict categories for all documents in the dataset\n",
    "predicted_categories = grid_search.best_estimator_.predict(data.data)\n",
    "\n",
    "# Print the predicted categories for the first few documents\n",
    "for i in range(5):\n",
    "    print(f\"Document {i + 1} - Predicted category: {data.target_names[predicted_categories[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of the first document:\n",
      "Subject: Re: There must be a creator! (Maybe)\n",
      "From: halat@pooh.bears (Jim Halat)\n",
      "Reply-To: halat@pooh.bears (Jim Halat)\n",
      "Lines: 24\n",
      "\n",
      "In article <16BA1E927.DRPORTER@SUVM.SYR.EDU>, DRPORTER@SUVM.SYR.EDU (Brad Porter) writes:\n",
      ">\n",
      ">   Science is wonderful at answering most of our questions.  I'm not the type\n",
      ">to question scientific findings very often, but...  Personally, I find the\n",
      ">theory of evolution to be unfathomable.  Could humans, a highly evolved,\n",
      ">complex organism that thinks, learns, and develops truly be an organism\n",
      ">that resulted from random genetic mutations and natural selection?\n",
      "\n",
      "[...stuff deleted...]\n",
      "\n",
      "Computers are an excellent example...of evolution without \"a\" creator.\n",
      "We did not \"create\" computers.  We did not create the sand that goes\n",
      "into the silicon that goes into the integrated circuits that go into\n",
      "processor board.  We took these things and put them together in an\n",
      "interesting way. Just like plants \"create\" oxygen using light through \n",
      "photosynthesis.  It's a much bigger leap to talk about something that\n",
      "created \"everything\" from nothing.  I find it unfathomable to resort\n",
      "to believing in a creator when a much simpler alternative exists: we\n",
      "simply are incapable of understanding our beginnings -- if there even\n",
      "were beginnings at all.  And that's ok with me.  The present keeps me\n",
      "perfectly busy.\n",
      "\n",
      "-jim halat\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access the first document in the training set\n",
    "first_document = data.data[1]\n",
    "\n",
    "# Print the content of the first document\n",
    "print(\"Content of the first document:\")\n",
    "print(first_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 815 - Predicted category: talk.religion.misc\n",
      "Document 651 - Predicted category: alt.atheism\n",
      "Document 382 - Predicted category: talk.religion.misc\n",
      "Document 45 - Predicted category: talk.religion.misc\n",
      "Document 591 - Predicted category: talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "# Set the number of documents to randomly select\n",
    "num_documents_to_select = 5  # You can adjust this number\n",
    "\n",
    "# Randomly select documents based on their file names\n",
    "random_documents_indices = random.sample(range(len(data.filenames)), num_documents_to_select)\n",
    "\n",
    "# Predict categories for the randomly selected documents\n",
    "for i in random_documents_indices:\n",
    "    predicted_category = grid_search.best_estimator_.predict([data.data[i]])\n",
    "    print(f\"Document {i + 1} - Predicted category: {data.target_names[predicted_category[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 146 - Predicted category: talk.religion.misc\n",
      "Document 461 - Predicted category: alt.atheism\n",
      "Document 6 - Predicted category: alt.atheism\n",
      "Document 42 - Predicted category: alt.atheism\n",
      "Document 9 - Predicted category: alt.atheism\n"
     ]
    }
   ],
   "source": [
    "# Set the number of documents to randomly select\n",
    "num_documents_to_select = 5  # You can adjust this number\n",
    "\n",
    "# Initialize a list to store document numbers\n",
    "DocPrint = []\n",
    "\n",
    "# Randomly select documents\n",
    "random_documents_indices = random.sample(range(len(data.data)), num_documents_to_select)\n",
    "\n",
    "# Predict categories for the randomly selected documents\n",
    "for i in random_documents_indices:\n",
    "    document_text = data.data[i]\n",
    "    predicted_category = grid_search.best_estimator_.predict([data.data[i]])\n",
    "    print(f\"Document {i + 1} - Predicted category: {data.target_names[predicted_category[0]]}\")\n",
    "    \n",
    "    # Save document number, content, and predicted category to the list\n",
    "    DocPrint.append((i + 1, document_text, data.target_names[predicted_category[0]]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Documents:\n",
      "Document 146 - Predicted category: talk.religion.misc\n",
      "Content:\n",
      "Subject: Re: Feminism and Islam, again\n",
      "From: kmagnacca@eagle.wesleyan.edu\n",
      "Organization: Wesleyan University\n",
      "Nntp-Posting-Host: wesleyan.edu\n",
      "Lines: 30\n",
      "\n",
      "In article <1993Apr14.030334.8650@ultb.isc.rit.edu>, snm6394@ultb.isc.rit.edu (S.N. Mozumder ) writes:\n",
      "> In article <1993Apr11.145519.1@eagle.wesleyan.edu> kmagnacca@eagle.wesleyan.edu writes:\n",
      ">>\n",
      ">>There's a way around that via the hadith, which state that silence is\n",
      ">>taken to mean \"yes\" and that women may not speak before a judge, who\n",
      ">>must conduct the marriage.\n",
      "> \n",
      "> Actaully, that's a false hadith, because it contradicts verses in the\n",
      "> Quran, that says women may testify- speak before a judge.\n",
      "> \n",
      "> Hadiths are declared false when they contradict the Quran.  Hadiths\n",
      "> weren't written during the revelation or during the life of the prophet,\n",
      "> and so may contain errors.\n",
      "\n",
      "So the only way you can tell a false hadith from a true one is\n",
      "if it contradicts the Quran?  What if it relates to something\n",
      "that isn't explicitly spelled out in the Quran?\n",
      "\n",
      "Also, the Quran wasn't written down during the life of Muhammed\n",
      "either.  It wasn't long after, but 20 years or so is still long\n",
      "enough to shift a few verses around.\n",
      "\n",
      "Karl\n",
      " -----------------------------------------------------------------------------\n",
      "| \"Lastly, I come to China in the hope      | \"All you touch and all you see  |\n",
      "| of fulfilling a lifelong ambition -       | Is all your life will ever be.\" |\n",
      "| dropping acid on the Great Wall.\"  --Duke |                 --Pink Floyd    |\n",
      "|-----------------------------------------------------------------------------|\n",
      "|         A Lie is still a Lie even if 3.8 billion people believe it.         |\n",
      " -----------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Document 461 - Predicted category: alt.atheism\n",
      "Content:\n",
      "From: keith@cco.caltech.edu (Keith Allan Schneider)\n",
      "Subject: Re: Objective morality (was Re: <Political Atheists?)\n",
      "Organization: California Institute of Technology, Pasadena\n",
      "Lines: 44\n",
      "NNTP-Posting-Host: lloyd.caltech.edu\n",
      "\n",
      "livesey@solntze.wpd.sgi.com (Jon Livesey) writes:\n",
      "\n",
      ">Humans have \"gone somewhat beyond\" what, exactly?    In one thread\n",
      ">you're telling us that natural morality is what animals do to\n",
      ">survive, and in this thread you are claiming that an omniscient\n",
      ">being can \"definitely\" say what is right and what is wrong.   So\n",
      ">what does this omniscient being use for a criterion?   The long-\n",
      ">term survival of the human species, or what?\n",
      "\n",
      "Well, that's the question, isn't it?  The goals are probably not all that\n",
      "obvious.  We can set up a few goals, like happiness and liberty and\n",
      "the golden rule, etc.  But these goals aren't inherent.  They have to\n",
      "be defined before an objective system is possible.\n",
      "\n",
      ">How does omniscient map into \"definitely\" being able to assign\n",
      ">\"right\" and \"wrong\" to actions?\n",
      "\n",
      "It is not too difficult, one you have goals in mind, and absolute\n",
      "knoweldge of everyone's intent, etc.\n",
      "\n",
      ">>Now you are letting an omniscient being give information to me.  This\n",
      ">>was not part of the original premise.\n",
      ">Well, your \"original premises\" have a habit of changing over time,\n",
      ">so perhaps you'd like to review it for us, and tell us what the\n",
      ">difference is between an omniscient being be able to assign \"right\"\n",
      ">and \"wrong\" to actions, and telling us the result, is. \n",
      "\n",
      "Omniscience is fine, as long as information is not given away.  Isn't\n",
      "this the resolution of the free will problem?  An interactive omniscient\n",
      "being changes the situation.\n",
      "\n",
      ">>Which type of morality are you talking about?  In a natural sense, it\n",
      ">>is not at all immoral to harm another species (as long as it doesn't\n",
      ">>adversely affect your own, I guess).\n",
      ">I'm talking about the morality introduced by you, which was going to\n",
      ">be implemented by this omniscient being that can \"definitely\" assign\n",
      ">\"right\" and \"wrong\" to actions.\n",
      ">You tell us what type of morality that is.\n",
      "\n",
      "Well, I was speaking about an objective system in general.  I didn't\n",
      "mention a specific goal, which would be necessary to determine the\n",
      "morality of an action.\n",
      "\n",
      "keith\n",
      "\n",
      "\n",
      "Document 6 - Predicted category: alt.atheism\n",
      "Content:\n",
      " howland.reston.ans.net!europa.eng.gtefsd.com!uunet!mcsun!Germany.EU.net!news.dfn.de!tubsibr!dbstu1.rz.tu-bs.de!I3150101\n",
      "Subject: Re: Gospel Dating\n",
      "From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Rosenau)\n",
      "Organization: Technical University Braunschweig, Germany\n",
      "Lines: 35\n",
      "\n",
      "In article <66015@mimsy.umd.edu>\n",
      "mangoe@cs.umd.edu (Charley Wingate) writes:\n",
      " \n",
      "(Deletion)\n",
      ">I cannot see any evidence for the V. B. which the cynics in this group would\n",
      ">ever accept.  As for the second, it is the foundation of the religion.\n",
      ">Anyone who claims to have seen the risen Jesus (back in the 40 day period)\n",
      ">is a believer, and therefore is discounted by those in this group; since\n",
      ">these are all ancients anyway, one again to choose to dismiss the whole\n",
      ">thing.  The third is as much a metaphysical relationship as anything else--\n",
      ">even those who agree to it have argued at length over what it *means*, so\n",
      ">again I don't see how evidence is possible.\n",
      ">\n",
      " \n",
      "No cookies, Charlie. The claims that Jesus have been seen are discredited\n",
      "as extraordinary claims that don't match their evidence. In this case, it\n",
      "is for one that the gospels cannot even agree if it was Jesus who has been\n",
      "seen. Further, there are zillions of other spook stories, and one would\n",
      "hardly consider others even in a religious context to be some evidence of\n",
      "a resurrection.\n",
      " \n",
      "There have been more elaborate arguments made, but it looks as if they have\n",
      "not passed your post filtering.\n",
      " \n",
      " \n",
      ">I thus interpret the \"extraordinary claims\" claim as a statement that the\n",
      ">speaker will not accept *any* evidence on the matter.\n",
      " \n",
      "It is no evidence in the strict meaning. If there was actual evidence it would\n",
      "probably be part of it, but the says nothing about the claims.\n",
      " \n",
      " \n",
      "Charlie, I have seen Invisible Pink Unicorns!\n",
      "By your standards we have evidence for IPUs now.\n",
      "   Benedikt\n",
      "\n",
      "\n",
      "Document 42 - Predicted category: alt.atheism\n",
      "Content:\n",
      "From: halat@pooh.bears (Jim Halat)\n",
      "Subject: Re: The Inimitable Rushdie (Re: An Anecdote about Islam\n",
      "Reply-To: halat@pooh.bears (Jim Halat)\n",
      "Lines: 33\n",
      "\n",
      "In article <115288@bu.edu>, jaeger@buphy.bu.edu (Gregg Jaeger) writes:\n",
      ">\n",
      ">He'd have to be precise about is rejection of God and his leaving Islam.\n",
      ">One is perfectly free to be muslim and to doubt and question the\n",
      ">existence of God, so long as one does not _reject_ God. I am sure that\n",
      ">Rushdie has be now made his atheism clear in front of a sufficient \n",
      ">number of proper witnesses. The question in regard to the legal issue\n",
      ">is his status at the time the crime was committed. \n",
      "\n",
      "\n",
      "I'd have to say that I have a problem with any organization, \n",
      "religious or not, where the idea that _simple speech_ such\n",
      "as this is the basis for a crime.\n",
      "\n",
      "-jim halat                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "                                                                          \n",
      "\n",
      "\n",
      "Document 9 - Predicted category: alt.atheism\n",
      "Content:\n",
      "From: healta@saturn.wwc.edu (Tammy R Healy)\n",
      "Subject: Re: Requests\n",
      "Lines: 53\n",
      "Organization: Walla Walla College\n",
      "Lines: 53\n",
      "\n",
      "In article <11857@vice.ICO.TEK.COM> bobbe@vice.ICO.TEK.COM (Robert Beauchaine) writes:\n",
      ">From: bobbe@vice.ICO.TEK.COM (Robert Beauchaine)\n",
      ">Subject: Re: Requests\n",
      ">Date: 19 Apr 93 18:25:08 GMT\n",
      ">In article <C5qLLG.4BC@mailer.cc.fsu.edu> mayne@cs.fsu.edu writes:\n",
      ">>\n",
      "(excess stuff deleted...)\n",
      "\n",
      "    \n",
      ">  However, it seems that a local church elder has been getting\n",
      ">  revelations from god about a devastating quake scheduled to level\n",
      ">  the area on May 3rd.  He has independent corroboration from\n",
      ">  several friends, who apparently have had similar revelations.  The\n",
      ">  5.7 quake was, in fact, in response to a request from the lot of\n",
      ">  them seeking a sign from god on the veracity of their visions.\n",
      ">\n",
      ">  None of this would be terribly interesting, except for the amount\n",
      ">  of stir it has created in the area.  Many, many people are taking\n",
      ">  these claims very seriously.  There are some making plans to be\n",
      ">  out of the are on the target date.  My local religious radio\n",
      ">  station devoted 4 hours of discussion on the topic.  \n",
      ">\n",
      ">  I even called up during one of the live broadcasts to tell the\n",
      ">  host that he would have a full account of my conversion on May\n",
      ">  4th, provided my family and I survived the devastation and ruin\n",
      ">  that will invariably follow the quake.\n",
      ">\n",
      ">/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\/\\ \n",
      ">\n",
      ">Bob Beauchaine bobbe@vice.ICO.TEK.COM \n",
      ">\n",
      ">They said that Queens could stay, they blew the Bronx away,\n",
      ">and sank Manhattan out at sea.\n",
      ">\n",
      ">^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "I know of a similar incident about 3 years ago.  A climatologist( Ithink \n",
      "that was his profession) named Iben Browning predicted that an earthquake \n",
      "would hit the New Madrid fault on Dec.3.  Some schools in Missouri that were \n",
      "on the fault line actually cancelled school for the day.  Many people \n",
      "evacuated New Madrid and other towns in teh are.  I wouldn't be suprised if \n",
      "there were more journalists in the area than residents.  Of course, teh \n",
      "earthquake never occured.  HOw do I know about his?  I used to live in \n",
      "Southern Illinois and the lican middle school was built directly on the \n",
      "fault line.  No we still had school... We laughed at the poor idiots who \n",
      "believed the prediction. :):):):)\n",
      "\n",
      "Bob, if you're wanting an excuse to convert to Christianity, you gonna have \n",
      "to look elsewhere.\n",
      "\n",
      "Tammy \"No Trim\" Healy\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print saved documents on another line\n",
    "print(\"Selected Documents:\")\n",
    "for doc_number, doc_content, predicted_category in DocPrint:\n",
    "    print(f\"Document {doc_number} - Predicted category: {predicted_category}\\nContent:\\n{doc_content}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Print the predicted categories for the first few documents\n",
    "for i in range(5):\n",
    "    result = {\n",
    "        \"Document\": i + 1,\n",
    "        \"Predicted category\": data.target_names[predicted_categories[i]],\n",
    "        \"Content\": None  # Placeholder for content\n",
    "    }\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the content of the first document to the results\n",
    "results.append({\"Content of the First Document\": first_document})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of documents to randomly select\n",
    "num_documents_to_select = 5  # You can adjust this number\n",
    "\n",
    "# Randomly select documents based on their file names\n",
    "random_documents_indices = random.sample(range(len(data.filenames)), num_documents_to_select)\n",
    "\n",
    "# Predict categories for the randomly selected documents\n",
    "for i in random_documents_indices:\n",
    "    predicted_category = grid_search.best_estimator_.predict([data.data[i]])\n",
    "    result = {\n",
    "        \"Document\": i + 1,\n",
    "        \"Predicted category\": data.target_names[predicted_category[0]],\n",
    "        \"Content\": None  # Placeholder for content\n",
    "    }\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of documents to randomly select\n",
    "num_documents_to_select = 5  # You can adjust this number\n",
    "\n",
    "# Initialize a list to store document numbers\n",
    "DocPrint = []\n",
    "\n",
    "# Randomly select documents\n",
    "random_documents_indices = random.sample(range(len(data.data)), num_documents_to_select)\n",
    "\n",
    "# Predict categories for the randomly selected documents\n",
    "for i in random_documents_indices:\n",
    "    document_text = data.data[i]\n",
    "    predicted_category = grid_search.best_estimator_.predict([data.data[i]])\n",
    "    result = {\n",
    "        \"Document\": i + 1,\n",
    "        \"Predicted category\": data.target_names[predicted_category[0]],\n",
    "        \"Content\": document_text\n",
    "    }\n",
    "    DocPrint.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df_results = pd.DataFrame(results + DocPrint)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_results.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a text file to save the results with explicit encoding\n",
    "with open('output.txt', 'w', encoding='utf-8') as txt_file:\n",
    "    # ... (your existing code)\n",
    "\n",
    "    # Print the results to the text file\n",
    "    for result in results + DocPrint:\n",
    "        print(result, file=txt_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict categories for all documents in the dataset using the ensemble model\n",
    "# predicted_categories_ensemble = ensemble_clf.predict(data.data)\n",
    "\n",
    "# # Print the predicted categories for the first few documents using the ensemble model\n",
    "# print(\"Ensemble Predictions for All Documents:\")\n",
    "# for i in range(5):\n",
    "#     print(f\"Document {i + 1} - Predicted category: {data.target_names[predicted_categories_ensemble[i]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predict categories for the randomly selected documents using the ensemble model\n",
    "# print(\"Ensemble Predictions for Selected Documents:\")\n",
    "# for i in random_documents_indices:\n",
    "#     predicted_category_ensemble = ensemble_clf.predict([data.data[i]])\n",
    "#     print(f\"Document {i + 1} - Predicted category: {data.target_names[predicted_category_ensemble[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the number of documents to randomly select\n",
    "# num_documents_to_select = 5  # You can adjust this number\n",
    "\n",
    "# # Initialize a list to store document numbers\n",
    "# DocPrint_ensemble = []\n",
    "\n",
    "# # Randomly select documents\n",
    "# random_documents_indices = random.sample(range(len(data.data)), num_documents_to_select)\n",
    "\n",
    "# # Predict categories for the randomly selected documents using the ensemble model\n",
    "# for i in random_documents_indices:\n",
    "#     document_text = data.data[i]\n",
    "#     predicted_category_ensemble = ensemble_clf.predict([data.data[i]])\n",
    "#     print(f\"Document {i + 1} - Predicted category (Ensemble): {data.target_names[predicted_category_ensemble[0]]}\")\n",
    "    \n",
    "#     # Save document number, content, and predicted category to the list\n",
    "#     DocPrint_ensemble.append((i + 1, document_text, data.target_names[predicted_category_ensemble[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print saved documents on another line using the ensemble model\n",
    "# print(\"Selected Documents (Ensemble):\")\n",
    "# for doc_number, doc_content, predicted_category_ensemble in DocPrint_ensemble:\n",
    "#     print(f\"Document {doc_number} - Predicted category (Ensemble): {predicted_category_ensemble}\\nContent:\\n{doc_content}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
