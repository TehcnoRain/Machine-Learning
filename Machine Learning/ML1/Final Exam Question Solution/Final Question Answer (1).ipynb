{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0f2b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "412750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/subashgandyer/datasets/main/great_customers.csv\"\n",
    "data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb3c0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "# Handle missing values (you can choose an appropriate strategy)\n",
    "# For example, filling missing numeric values with the mean and missing categorical values with the most frequent category\n",
    "data['age'].fillna(data['age'].mean(), inplace=True)\n",
    "data['salary'].fillna(data['salary'].mean(), inplace=True)\n",
    "data['education_rank'].fillna(data['education_rank'].median(), inplace=True)\n",
    "data['tea_per_year'].fillna(data['tea_per_year'].median(), inplace=True)\n",
    "data['coffee_per_year'].fillna(data['coffee_per_year'].median(), inplace=True)\n",
    "data['mins_beerdrinking_year'].fillna(0, inplace=True)\n",
    "data['mins_exercising_year'].fillna(0, inplace=True)\n",
    "data['works_hours'].fillna(data['works_hours'].median(), inplace=True)\n",
    "\n",
    "# Check for missing values again after handling them\n",
    "missing_values_after = data.isnull().sum()\n",
    "data.to_csv(\"cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a1e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2963db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of        user_id   age      workclass        salary  education_rank  \\\n",
       "0      1004889  14.0        private  70773.000000               9   \n",
       "1      1012811  25.0        private  76597.000000               9   \n",
       "2      1006870  21.0        private  47947.250000              10   \n",
       "3      1022149  23.0        private  41740.250000               7   \n",
       "4      1029558  26.0        private  37149.297355               9   \n",
       "...        ...   ...            ...           ...             ...   \n",
       "13594  1016807  42.0        private  55293.000000              13   \n",
       "13595  1038859  58.0  self_employed  25928.250000              14   \n",
       "13596  1041214  75.0  self_employed  16590.000000               7   \n",
       "13597  1038013  45.0        private  25536.750000              11   \n",
       "13598  1017676  42.0        private  57656.000000               6   \n",
       "\n",
       "      marital-status occupation           race     sex  \\\n",
       "0      Never-married      sales  not_caucasian    Male   \n",
       "1           Divorced      sales      caucasian  Female   \n",
       "2      Never-married   clerical      caucasian  Female   \n",
       "3           Divorced      sales      caucasian  Female   \n",
       "4            Married      sales  not_caucasian    Male   \n",
       "...              ...        ...            ...     ...   \n",
       "13594        Married  executive      caucasian    Male   \n",
       "13595        Married      sales      caucasian    Male   \n",
       "13596        Married  executive      caucasian    Male   \n",
       "13597       Divorced  executive      caucasian    Male   \n",
       "13598  Never-married    trucker      caucasian    Male   \n",
       "\n",
       "       mins_beerdrinking_year  mins_exercising_year  works_hours  \\\n",
       "0                         0.0                   0.0           40   \n",
       "1                         0.0                   0.0           30   \n",
       "2                         0.0                   0.0           10   \n",
       "3                         0.0                   0.0           20   \n",
       "4                         0.0                   0.0           36   \n",
       "...                       ...                   ...          ...   \n",
       "13594                     0.0                   0.0           40   \n",
       "13595                     0.0                   0.0           40   \n",
       "13596                     0.0                   0.0           35   \n",
       "13597                     0.0                   0.0           40   \n",
       "13598                     0.0                   0.0           40   \n",
       "\n",
       "       tea_per_year  coffee_per_year  great_customer_class  \n",
       "0             399.0            447.0                     0  \n",
       "1             256.0            447.0                     0  \n",
       "2             442.0            276.0                     0  \n",
       "3             175.0            447.0                     0  \n",
       "4             175.0            120.0                     0  \n",
       "...             ...              ...                   ...  \n",
       "13594         277.0            268.0                     1  \n",
       "13595         337.0            447.0                     1  \n",
       "13596         175.0            447.0                     1  \n",
       "13597          99.0             79.0                     1  \n",
       "13598          24.0            373.0                     1  \n",
       "\n",
       "[13599 rows x 15 columns]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebbbe1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'age', 'workclass', 'salary', 'education_rank',\n",
      "       'marital-status', 'occupation', 'race', 'sex', 'mins_beerdrinking_year',\n",
      "       'mins_exercising_year', 'works_hours', 'tea_per_year',\n",
      "       'coffee_per_year', 'great_customer_class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f59bbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = data.drop(columns=['great_customer_class'])\n",
    "y = data['great_customer_class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd3a4b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9393382352941176\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      2476\n",
      "           1       0.81      0.43      0.56       244\n",
      "\n",
      "    accuracy                           0.94      2720\n",
      "   macro avg       0.88      0.71      0.76      2720\n",
      "weighted avg       0.93      0.94      0.93      2720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing steps\n",
    "numeric_features = ['age', 'mins_beerdrinking_year', 'mins_exercising_year', 'works_hours', 'tea_per_year', 'coffee_per_year']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Replace missing values with median\n",
    "    ('scaler', StandardScaler())  # Standardize features\n",
    "])\n",
    "\n",
    "categorical_features = ['workclass', 'education_rank', 'marital-status', 'occupation', 'race', 'sex']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Replace missing values with most frequent\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical variables\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define the classifiers you want to use\n",
    "classifier1 = RandomForestClassifier(random_state=42)\n",
    "classifier2 = GradientBoostingClassifier(random_state=42)\n",
    "classifier3 = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('rf', classifier1),\n",
    "    ('gb', classifier2),\n",
    "    ('lr', classifier3)\n",
    "], voting='soft')  # Use 'soft' voting for probabilities\n",
    "\n",
    "# Create a pipeline with preprocessing and the voting classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', voting_classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model (you can replace this with your preferred evaluation metrics)\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Classification Report:\\n{report}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f891d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(\"Random Forest has the best accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cedce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.9261029411764706\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      2476\n",
      "           1       0.96      0.18      0.31       244\n",
      "\n",
      "    accuracy                           0.93      2720\n",
      "   macro avg       0.94      0.59      0.64      2720\n",
      "weighted avg       0.93      0.93      0.90      2720\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # Add this import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import OneHotEncoder  # Import OneHotEncoder\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_features = ['workclass', 'marital-status', 'occupation', 'race', 'sex']\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_categorical_encoded = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "# Combine the encoded categorical features with the numerical features\n",
    "X_encoded = np.hstack((X_categorical_encoded, X.drop(columns=categorical_features).values))\n",
    "\n",
    "# Define X and y (your feature matrix and target variable)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature selection (e.g., using SelectKBest with ANOVA F-statistic)\n",
    "k_best = SelectKBest(score_func=f_classif, k=5)\n",
    "X_train_selected = k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = k_best.transform(X_test)\n",
    "\n",
    "# Define and train the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='linear', random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb94617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Perform one-hot encoding for categorical features\n",
    "categorical_features = ['workclass', 'marital-status', 'occupation', 'race', 'sex']\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_categorical_encoded = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "# Combine the encoded categorical features with the numerical features\n",
    "X_encoded = np.hstack((X_categorical_encoded, X.drop(columns=categorical_features).values))\n",
    "\n",
    "# Define X and y (your feature matrix and target variable)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature selection (e.g., using SelectKBest with ANOVA F-statistic)\n",
    "k_best = SelectKBest(score_func=f_classif, k=5)\n",
    "X_train_selected = k_best.fit_transform(X_train, y_train)\n",
    "X_test_selected = k_best.transform(X_test)\n",
    "\n",
    "# Define and train the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Support Vector Machine': SVC(kernel='linear', random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f58bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "\n",
    "# Train and evaluate the Support Vector Machine (SVM) model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n",
    "\n",
    "# Train and evaluate the Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)\n",
    "\n",
    "# Train and evaluate the Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(\"Naive Bayes Accuracy:\", nb_accuracy)\n",
    "\n",
    "# Train and evaluate the K-Nearest Neighbors (KNN) model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_predictions = knn_model.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "print(\"K-Nearest Neighbors Accuracy:\", knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa654196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cde4e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
